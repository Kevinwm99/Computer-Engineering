{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "## Name: Vuong Minh Phu\n",
    "## Student ID: 202050798\n",
    "## Class: Computer Engineering\n",
    "## Instructor: Prof. Seung-Hoon Na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<mark> Problem 4.5 </mark>**\n",
    "\n",
    "Prove that the normalization constant for a d-dimensional Gaussian is given by\n",
    "\n",
    "\\begin{equation}\n",
    "(2\\pi)^{d/2} |\\Sigma|^\\frac{1}{2} = \\int exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))dx\n",
    "\\end{equation}\n",
    "\n",
    "We have: $ \\Sigma = U\\Lambda U^T $\n",
    "\n",
    "\\begin{equation}\n",
    "\\int exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))dx = \\int exp(-\\frac{1}{2}(x-\\mu)^TU \\Lambda^{-1}U^{T} (x-\\mu))dx\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "where U is an orthogonal matrix $ (U^{-1} = U^T) $, we can derive Eq. 1. Then we perform coordinate changing $ y = U^T(x-\\mu) $\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\int exp(-\\frac{1}{2}(x-\\mu)^TU \\Lambda^{-1}U^{T} (x-\\mu))dx = \\int exp(-\\frac{1}{2} y^T \\Lambda^{-1}y)dx = \\\\\n",
    "\\int exp(-\\frac{1}{2} \\sum_i \\frac{y_i^2}{\\lambda_i})dx = \\int exp(-\\frac{1}{2} \\sum_i \\frac{y_i^2}{\\lambda_i}) \\frac{\\partial (x1,x2,\\dots,xn)}{\\partial(y1,y2,\\dots,yn)}dy\n",
    "\\end{split}\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "To change the vector of intergration from dx to dy, we need to compute the Jacobian.\n",
    "\\begin{equation}\n",
    "y = U^T(x-\\mu) \\Rightarrow x = Uy +\\mu \\\\\n",
    "J_{ij} = \\frac{\\partial x_i}{\\partial y_i} = u_{ij}\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, $J = U$ and $ \\frac{\\partial (x1,x2,\\dots,xn)}{\\partial(y1,y2,\\dots,yn)} = \\det(U) $. Because U is orthogonal, we have $ \\det(U) = \\pm 1 $. We also know that $ \\exp(f(y)) $ is always positive $\\Rightarrow $ $\\det(U) =1 $. \n",
    "\n",
    "Therefore, the expression becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "\\int \\exp(-\\frac{1}{2} \\sum_i \\frac{y_i^2}{\\lambda_i})dy = \\prod_i \\int \\exp(-\\frac{1}{2} \\frac{y_i^2}{\\lambda_i})d y_i\n",
    "\\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "From the Gaussian properties $ \\int exp(-\\frac{x^2}{2 \\sigma^2})dx = \\sqrt{(2\\pi \\sigma^2)} $. Then the Eq.4 becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "\\prod_i \\int exp(-\\frac{1}{2} \\frac{y_i^2}{\\lambda_i})d y_i = \\prod_{i=1}^{d} \\sqrt{(2\\pi \\lambda_i)} = \\sqrt{(2\\pi)^d} \\prod_{i=1}^{d} \\sqrt{\\lambda_i} = (2\\pi)^\\frac{d}{2}|\\Sigma|^\\frac{1}{2}\n",
    "\\tag{5}\n",
    "\\end{equation}\n",
    "where $|\\Sigma| = \\prod \\lambda_i $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<mark> Problem 4.7 </mark>**\n",
    "\n",
    "<em> Consider a bivariate Gaussian distribution  $p(x_1,x_2) = N (x|\\mu,\\Sigma)$ where \n",
    "\\begin{equation}\n",
    "\\Sigma = \\begin{pmatrix} \n",
    "\\sigma^2_1 & \\sigma_{12} \\\\ \n",
    "\\sigma_{21} & \\sigma^2_2  \n",
    "\\end{pmatrix} = \\sigma_1 \\sigma_2 \\begin{pmatrix} \n",
    "\\frac{\\sigma_1}{\\sigma_2} & \\rho \\\\ \n",
    "\\rho & \\frac{\\sigma_1}{\\sigma_2} \n",
    "\\end{pmatrix}\n",
    "\\tag{4.269}\n",
    "\\end{equation}\n",
    "    \n",
    "where the correlation coefficient is given by \n",
    "    \n",
    "\\begin{equation}\n",
    "\\rho \\overset{\\Delta}{=} \\frac{\\sigma_{12}}{\\sigma_1 \\sigma_2}\n",
    "\\tag{4.270}\n",
    "\\end{equation} </em>\n",
    "\n",
    "**a)** Since $x_1, x_2$ have a multivariate Gaussian distribution, the conditional $p(x_2|x_1)$ is also Gaussian. We have:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(x_2|x_1) = N(x_2|\\mu_{2|1},|\\Sigma_{2|1}) \\\\\n",
    "\\mu_{2|1} = \\mu_2 + \\Sigma_{21}\\Sigma_{11}^{-1}(x_1-\\mu_1)\\\\\n",
    "\\Sigma_{2|1} = \\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\n",
    "\\end{split}\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "For the bivariate Gaussian, the vectors $ \\mu_2, \\mu_1$ and the matrix partitions $\\Sigma_{ij}$ become scalars. Therefore:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mu_{2|1} = \\mu_2 + \\Sigma_{21}\\Sigma_{11}^{-1}(x_1-\\mu_1) =\\mu_2 + \\rho \\frac{\\sigma_2}{\\sigma_1}(x_1-\\mu_1)\\\\\n",
    "\\Sigma_{2|1} = \\Sigma_{22}-\\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12} = \\sigma_2^2-\\frac{\\sigma_{21}\\sigma_{12}}{\\sigma_1^2} = \\sigma_2^2(1-\\rho^2)\n",
    "\\end{split}\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Using (2), we get:\n",
    "\n",
    "\\begin{equation}\n",
    "p(x_2|x_1) = N(x_2|\\mu_2+\\rho\\frac{\\sigma_2}{\\sigma_1}(x_1-\\mu_1),\\sigma_2^2 (1-\\rho^2))\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "**b)** Assuming $\\sigma_1 = \\sigma_2 = 1$ we can write Eq.3 as follow: \n",
    "\n",
    "\\begin{equation}\n",
    " p(x_2|x_1) = N(x_2|\\mu_2+\\rho(x_1-\\mu_1), (1-\\rho^2)) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<mark> Problem 4.11 </mark>**\n",
    "\n",
    "Derive $ p(\\mu,\\Sigma|D) = NIW(\\mu,\\Sigma|m_N,\\kappa_N,\\nu_N,S_N) $ by showing that \n",
    "\n",
    "\\begin{equation}\n",
    "N(\\bar{x}-\\mu)(\\bar{x}-\\mu)^T+\\kappa_0(\\mu-m_0)(\\mu-m_0)^T \\\\\n",
    "=\\kappa_{N}(\\mu-m_N)(\\mu-m_N)^T+\\frac{\\kappa_0N}{K_N}(\\bar{x}-m_0)(\\bar{x}-m_0)^T\n",
    "\\end{equation}\n",
    "\n",
    "**Solution:**\n",
    "The likelihood is:\n",
    "\n",
    "\\begin{equation}\n",
    "p(D|\\mu,\\Sigma)\\alpha |\\Sigma|^{-\\frac{N}{2}}\\exp(-\\frac{N}{2}(\\mu-\\bar{x})^T\\Sigma^{-1}(\\mu-\\bar{x}))\\exp(-\\frac{1}{2}tr(\\Sigma^{-1}S_x))\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "We also know that the conjugate prior is:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\mu,\\Sigma) = NIW(\\mu,\\Sigma|m_0,\\kappa_0,\\nu_0,S_0)\\ \\alpha \\\\\n",
    "|\\Sigma|^{-\\frac{\\nu_0+D+2}{2}}\\exp(-\\frac{\\kappa_0}{2}(\\mu-m_0)^T\\Sigma^{-1}(\\mu-m_0)-\\frac{1}{2}tr(\\Sigma^{-1}S_0))\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, the posterior is proportional to:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\mu,\\Sigma|D)\\ \\alpha\\ p(D|\\mu,\\Sigma)p(\\mu,\\Sigma)\\ \\alpha \\\\\n",
    "|\\Sigma|^{-\\frac{N}{2}}\\exp(-\\frac{N}{2}(\\mu-\\bar{x})^T\\Sigma^{-1}(\\mu-\\bar{x}))\\exp(-\\frac{1}{2}tr(\\Sigma^{-1}S_{\\bar{x}}))\\\\\n",
    "|\\Sigma|^{-\\frac{\\nu_0+D+2}{2}}\\exp(-\\frac{\\kappa_0}{2}(\\mu-m_0)^T\\Sigma^{-1}(\\mu-m_0)-\\frac{1}{2}tr(\\Sigma^{-1}S_0)) = \\\\\n",
    "|\\Sigma|^{-\\frac{\\nu_0+D+2+N}{2}}\\exp(-\\frac{N}{2}(\\mu-\\bar{x})^T\\Sigma^{-1}(\\mu-\\bar{x})-\\frac{\\kappa_0}{2}(\\mu-m_0)^T\\Sigma^{-1}(\\mu-m_0))\\\\\n",
    "\\exp(-\\frac{1}{2}tr(\\Sigma^{-1}S_x)-\\frac{1}{2}tr(\\Sigma^{-1}S_0))\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "In the psterior, we have $ |\\Sigma|^{-\\frac{\\nu_0+D+2+N}{2}} $, because D is fixed, then the only parameter left to update is \n",
    "$\\nu_0$. Thus $\\nu_0 = \\nu_0 +N $. \n",
    "\n",
    "After that is the quadratic form expressions, we only need to derive $  \\exp(-\\frac{N}{2}(\\mu-\\bar{x})^T\\Sigma^{-1}(\\mu-\\bar{x})-\\frac{\\kappa_0}{2}(\\mu-m_0)^T\\Sigma^{-1}(\\mu-m_0)) $.\n",
    "\n",
    "From 4.6.3.1, we know that:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=0}^{N}(x_i-\\mu)\\Sigma^{-1}(x_i-\\mu)=tr(\\Sigma^{-1}S_{\\bar{x}})+N(\\bar{x}-\\mu)^T\\Sigma^{-1}(\\bar{x}-\\mu)\n",
    "\\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "Thus \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "N(\\mu-\\bar{x})^T\\Sigma^{-1}(\\mu-\\bar{x})+\\kappa_0(\\mu-m_0)^T\\Sigma^{-1}(\\mu-m_0)=\\\\\n",
    "\\\\\n",
    "tr(\\Sigma^{-1}S_{m_N})+(N+\\kappa_0)(m_N-\\mu)^T\\Sigma^{-1}(m_N-\\mu)\\\\\n",
    "\\\\\n",
    "m_N=\\frac{sumAllTerms}{numberOfTerms}=\\frac{\\kappa_0m_0+N\\bar{x}}{\\kappa_0+N}\\\\\n",
    "\\\\\n",
    "S_{m_N}=N(\\bar{x}-m_N)(\\bar{x}-m_N)^T=\\\\\n",
    "\\\\\n",
    "\\frac{N_{\\kappa_0}}{N+\\kappa_0}(\\bar{x}-m_0)(\\bar{x}-m_0)^T\n",
    "\\end{split}\n",
    "\\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "We also have $ tr(\\Sigma^{-1}S_0)+tr(\\Sigma^{-1}S_{\\bar{x}})+tr(\\Sigma^{-1}S_{m_N}) = tr(\\Sigma^{-1}(S_0+S_{\\bar{x}}+S_{m_N}))$\n",
    "\n",
    "Finally, we need to combine all the new terms and update the remaining parameters:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(\\mu,\\Sigma)\\ \\alpha\\ |\\Sigma|^{-\\frac{\\nu_N+D+2}{2}}\\exp(-\\frac{N+\\kappa_0}{2}(m_N-\\mu)^T\\Sigma^{-1}(m_N-\\mu))\\\\\n",
    "exp(-\\frac{1}{2}tr\\Sigma&^{-1}(S_0+S_{m_N}+S_{\\bar{x}})) = \\\\\n",
    "|\\Sigma|^{-\\frac{\\nu_N+D+2}{2}}\\exp(-\\frac{\\kappa_N}{2}(\\mu- m_N)^T|\\Sigma|^{-1}(\\mu- m_N)-\\frac{1}{2}tr(\\Sigma^{-1}S_N))\n",
    "\\end{split}\n",
    "\\tag{6}\n",
    "\\end{equation}\n",
    "\n",
    "The posterior is given by the following distributions:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(\\mu,\\Sigma) = NIW(\\mu,\\Sigma|m_N,\\kappa_N,\\nu_N,S_N)\\\\\n",
    "m_N=\\frac{\\kappa_0m_0+N\\bar{x}}{\\kappa_0+N}\\\\\n",
    "\\kappa_N=\\kappa_0+N\\\\\n",
    "\\nu_N=\\nu_0+N\\\\\n",
    "S_N = S_0+S_{\\bar{x}}+S_{m_N}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<mark> Problem 4.22 </mark>**\n",
    "\n",
    "Given the prior probabilities of thress category classification:\n",
    "$$ P(Y=1) = P(Y=2) = P(Y=3) $$\n",
    "\n",
    "The class-condiional densities are NVM with parameters:\n",
    "$$ \\mu_1=[0,0]^T,\\mu_2=[1,1]^T,\\mu_3=[-1,1]^T $$\n",
    "\n",
    "and $$ \\Sigma_1 = \\begin{bmatrix}\n",
    "0.7 & 0\\\\\n",
    "0 & 0.7\n",
    " \\end{bmatrix},\n",
    " \\Sigma_2 = \\begin{bmatrix}\n",
    "0.8 & 0.2\\\\\n",
    "0.2 & 0.8\n",
    " \\end{bmatrix},\n",
    " \\Sigma_3 = \\begin{bmatrix}\n",
    "0.8 & 0.2\\\\\n",
    "0.8 & 0.8\n",
    " \\end{bmatrix} $$\n",
    "\n",
    " Classify\n",
    " \n",
    " a. $x =[-0.5,0.5] $\n",
    "\n",
    " b. $x =[0.5,0.5] $\n",
    " \n",
    " **Solution:**\n",
    "\n",
    " In order to classify the points we need to calculate the NVM distributions for each of them. The classification of each point is based on which class produce the bigger posterior distribution. Since the prior of three classes are the same, the Gaussian class conditional is responsible to determine the bigger score.\n",
    "\n",
    " We have the pdf for NVM is:\n",
    " \\begin{equation}\n",
    " f(x) = \\frac{1}{\\sqrt{(2\\pi)^k\\det(\\Sigma)}}\\exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))\n",
    " \\end{equation}\n",
    "\n",
    " For each point we need to calculate the pdf for it with each $\\mu$ and $\\Sigma$ values\n",
    " Hence, we can use numpy and scipy libraries to calculate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "mu_1 = np.array([0, 0])\n",
    "mu_2 = np.array([1, 1])\n",
    "mu_3 = np.array([-1, 1])\n",
    "\n",
    "Sigma_1 = np.array([[0.7, 0], [0, 0.7]]) \n",
    "Sigma_2 = np.array([[0.8, 0.2], [0.2, 0.8]])\n",
    "Sigma_3 = np.array([[0.8, 0.2], [0.2, 0.8]])\n",
    "\n",
    "x_1 = np.array([-0.5, 0.5])\n",
    "x_2 = np.array([0.5, 0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pdf for x1 are:  0.15908048981271555 0.04983035606132821 0.13545295138715246\n"
     ]
    }
   ],
   "source": [
    "fx1=  multivariate_normal.pdf(x_1, mu_1, Sigma_1)\n",
    "fx2=  multivariate_normal.pdf(x_1, mu_2, Sigma_2)\n",
    "fx3=  multivariate_normal.pdf(x_1, mu_3, Sigma_3)\n",
    "\n",
    "print(\"the pdf for x1 are: \",fx1,fx2,fx3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, for question a we will classify x as **Class 1**\n",
    "\n",
    "We will do the same for **question b** and get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pdf for x1 are:  0.15908048981271555 0.1600187545745967 0.03022363873559281\n"
     ]
    }
   ],
   "source": [
    "fx1=  multivariate_normal.pdf(x_2, mu_1, Sigma_1)\n",
    "fx2=  multivariate_normal.pdf(x_2, mu_2, Sigma_2)\n",
    "fx3=  multivariate_normal.pdf(x_2, mu_3, Sigma_3)\n",
    "\n",
    "print(\"the pdf for x1 are: \",fx1,fx2,fx3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We classifiy x as **Class 2**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
